{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f062760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "import importlib\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a44771",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from envs.pendulum import PendulumEnv as baseline\n",
    "\n",
    "env = baseline(render_mode='human')\n",
    "\n",
    "n_actions = env.action_space.shape[-1]\n",
    "print(env.action_space)\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "model = SAC(\"MlpPolicy\", env, action_noise=action_noise, verbose=1)\n",
    "model.learn(total_timesteps=10000, log_interval=10)\n",
    "model.save(\"./saved_models/sac_baseline\")\n",
    "env = model.get_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a59cb4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(-1.0, 1.0, (1,), float32)\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32       |\n",
      "|    ep_rew_mean     | -23.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 10       |\n",
      "|    fps             | 27       |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 320      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.21     |\n",
      "|    critic_loss     | 0.0743   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 204      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 25.4     |\n",
      "|    ep_rew_mean     | -24.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 27       |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 507      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.47     |\n",
      "|    critic_loss     | 0.42     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 392      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.1     |\n",
      "|    ep_rew_mean     | -24.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 30       |\n",
      "|    fps             | 27       |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 692      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.46     |\n",
      "|    critic_loss     | 0.671    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 576      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.1     |\n",
      "|    ep_rew_mean     | -25.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 27       |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 882      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.96     |\n",
      "|    critic_loss     | 0.507    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 766      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.4     |\n",
      "|    ep_rew_mean     | -25.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 50       |\n",
      "|    fps             | 27       |\n",
      "|    time_elapsed    | 39       |\n",
      "|    total_timesteps | 1070     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 6.25     |\n",
      "|    critic_loss     | 0.247    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 954      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.9     |\n",
      "|    ep_rew_mean     | -25.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 27       |\n",
      "|    time_elapsed    | 46       |\n",
      "|    total_timesteps | 1255     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 7.19     |\n",
      "|    critic_loss     | 0.128    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1139     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.6     |\n",
      "|    ep_rew_mean     | -25.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 70       |\n",
      "|    fps             | 26       |\n",
      "|    time_elapsed    | 53       |\n",
      "|    total_timesteps | 1441     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 8.32     |\n",
      "|    critic_loss     | 0.147    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1325     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.4     |\n",
      "|    ep_rew_mean     | -25.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 27       |\n",
      "|    time_elapsed    | 63       |\n",
      "|    total_timesteps | 1714     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 7.09     |\n",
      "|    critic_loss     | 0.0808   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1523     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.3     |\n",
      "|    ep_rew_mean     | -25.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 90       |\n",
      "|    fps             | 27       |\n",
      "|    time_elapsed    | 87       |\n",
      "|    total_timesteps | 2365     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.56     |\n",
      "|    critic_loss     | 0.342    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2126     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 74.5     |\n",
      "|    ep_rew_mean     | -29.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 27       |\n",
      "|    time_elapsed    | 270      |\n",
      "|    total_timesteps | 7449     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.36     |\n",
      "|    critic_loss     | 0.134    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 6136     |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "from envs.pendulum import PendulumEnv as baseline\n",
    "\n",
    "env = baseline(render_mode='human')\n",
    "\n",
    "n_actions = env.action_space.shape[-1]\n",
    "print(env.action_space)\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "model = DDPG(\"MlpPolicy\", env, action_noise=action_noise, verbose=1)\n",
    "model.learn(total_timesteps=10000, log_interval=10)\n",
    "model.save(\"./saved_models/ddpg_baseline\")\n",
    "env = model.get_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bda5cddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(-1.0, 1.0, (1,), float32)\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 25.6     |\n",
      "|    ep_rew_mean     | -27      |\n",
      "| time/              |          |\n",
      "|    episodes        | 10       |\n",
      "|    fps             | 28       |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 256      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0893   |\n",
      "|    critic_loss     | 0.0382   |\n",
      "|    ent_coef        | 0.955    |\n",
      "|    ent_coef_loss   | -0.0777  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 155      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.6     |\n",
      "|    ep_rew_mean     | -27.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 28       |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 492      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.833    |\n",
      "|    critic_loss     | 0.117    |\n",
      "|    ent_coef        | 0.89     |\n",
      "|    ent_coef_loss   | -0.195   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 391      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.2     |\n",
      "|    ep_rew_mean     | -26      |\n",
      "| time/              |          |\n",
      "|    episodes        | 30       |\n",
      "|    fps             | 28       |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 667      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.18     |\n",
      "|    critic_loss     | 0.314    |\n",
      "|    ent_coef        | 0.844    |\n",
      "|    ent_coef_loss   | -0.283   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 566      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.4     |\n",
      "|    ep_rew_mean     | -23.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 28       |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 816      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.6      |\n",
      "|    critic_loss     | 0.591    |\n",
      "|    ent_coef        | 0.808    |\n",
      "|    ent_coef_loss   | -0.35    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 715      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.2     |\n",
      "|    ep_rew_mean     | -24.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 50       |\n",
      "|    fps             | 29       |\n",
      "|    time_elapsed    | 45       |\n",
      "|    total_timesteps | 1309     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.71     |\n",
      "|    critic_loss     | 0.363    |\n",
      "|    ent_coef        | 0.699    |\n",
      "|    ent_coef_loss   | -0.543   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1208     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.6     |\n",
      "|    ep_rew_mean     | -23.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 28       |\n",
      "|    time_elapsed    | 51       |\n",
      "|    total_timesteps | 1478     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.03     |\n",
      "|    critic_loss     | 0.327    |\n",
      "|    ent_coef        | 0.666    |\n",
      "|    ent_coef_loss   | -0.642   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1377     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.2     |\n",
      "|    ep_rew_mean     | -23      |\n",
      "| time/              |          |\n",
      "|    episodes        | 70       |\n",
      "|    fps             | 29       |\n",
      "|    time_elapsed    | 63       |\n",
      "|    total_timesteps | 1833     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.1      |\n",
      "|    critic_loss     | 0.188    |\n",
      "|    ent_coef        | 0.602    |\n",
      "|    ent_coef_loss   | -0.716   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1732     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33       |\n",
      "|    ep_rew_mean     | -24.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 29       |\n",
      "|    time_elapsed    | 90       |\n",
      "|    total_timesteps | 2639     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.29     |\n",
      "|    critic_loss     | 0.0544   |\n",
      "|    ent_coef        | 0.48     |\n",
      "|    ent_coef_loss   | -1.09    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 2538     |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "from envs.pendulum_fullRandom import PendulumEnv as full_random\n",
    "\n",
    "env = full_random(render_mode='human')\n",
    "\n",
    "n_actions = env.action_space.shape[-1]\n",
    "print(env.action_space)\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "model = SAC(\"MlpPolicy\", env, action_noise=action_noise, verbose=1)\n",
    "model.learn(total_timesteps=10000, log_interval=10)\n",
    "model.save(\"./saved_models/sac_fullRandom\")\n",
    "env = model.get_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e37b2bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(-1.0, 1.0, (1,), float32)\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 63.4     |\n",
      "|    ep_rew_mean     | -36.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 10       |\n",
      "|    fps             | 27       |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 634      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.952    |\n",
      "|    critic_loss     | 0.115    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 533      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 312      |\n",
      "|    ep_rew_mean     | -32.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 27       |\n",
      "|    time_elapsed    | 225      |\n",
      "|    total_timesteps | 6231     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.48     |\n",
      "|    critic_loss     | 0.0539   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4985     |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "from envs.pendulum_fullRandom import PendulumEnv as full_random\n",
    "\n",
    "env = full_random(render_mode='human')\n",
    "\n",
    "n_actions = env.action_space.shape[-1]\n",
    "print(env.action_space)\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "model = DDPG(\"MlpPolicy\", env, action_noise=action_noise, verbose=1)\n",
    "model.learn(total_timesteps=10000, log_interval=10)\n",
    "model.save(\"./saved_models/ddpg_fullRandom\")\n",
    "env = model.get_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1768311f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(-1.0, 1.0, (1,), float32)\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.6     |\n",
      "|    ep_rew_mean     | -16.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 10       |\n",
      "|    fps             | 28       |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 206      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.235   |\n",
      "|    critic_loss     | 0.313    |\n",
      "|    ent_coef        | 0.969    |\n",
      "|    ent_coef_loss   | -0.0522  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 105      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.9     |\n",
      "|    ep_rew_mean     | -18.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 28       |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 457      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.215    |\n",
      "|    critic_loss     | 0.323    |\n",
      "|    ent_coef        | 0.899    |\n",
      "|    ent_coef_loss   | -0.179   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 356      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 25.3     |\n",
      "|    ep_rew_mean     | -17.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 30       |\n",
      "|    fps             | 28       |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 759      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.21     |\n",
      "|    critic_loss     | 0.502    |\n",
      "|    ent_coef        | 0.821    |\n",
      "|    ent_coef_loss   | -0.328   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 658      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 27.1     |\n",
      "|    ep_rew_mean     | -17.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 29       |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 1085     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.58     |\n",
      "|    critic_loss     | 0.551    |\n",
      "|    ent_coef        | 0.745    |\n",
      "|    ent_coef_loss   | -0.486   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 984      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.3     |\n",
      "|    ep_rew_mean     | -16.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 50       |\n",
      "|    fps             | 29       |\n",
      "|    time_elapsed    | 50       |\n",
      "|    total_timesteps | 1465     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.0856  |\n",
      "|    critic_loss     | 0.667    |\n",
      "|    ent_coef        | 0.666    |\n",
      "|    ent_coef_loss   | -0.664   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1364     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28.5     |\n",
      "|    ep_rew_mean     | -16.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 29       |\n",
      "|    time_elapsed    | 58       |\n",
      "|    total_timesteps | 1708     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.596    |\n",
      "|    critic_loss     | 0.287    |\n",
      "|    ent_coef        | 0.62     |\n",
      "|    ent_coef_loss   | -0.759   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1607     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31       |\n",
      "|    ep_rew_mean     | -17.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 70       |\n",
      "|    fps             | 29       |\n",
      "|    time_elapsed    | 74       |\n",
      "|    total_timesteps | 2169     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.909    |\n",
      "|    critic_loss     | 0.469    |\n",
      "|    ent_coef        | 0.543    |\n",
      "|    ent_coef_loss   | -0.927   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 2068     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 118      |\n",
      "|    ep_rew_mean     | -17.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 29       |\n",
      "|    time_elapsed    | 315      |\n",
      "|    total_timesteps | 9454     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.16    |\n",
      "|    critic_loss     | 0.0147   |\n",
      "|    ent_coef        | 0.0665   |\n",
      "|    ent_coef_loss   | -3.41    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9353     |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "from envs.pendulum_piecewiseReward import PendulumEnv as piecewise\n",
    "\n",
    "env = piecewise(render_mode='human')\n",
    "\n",
    "n_actions = env.action_space.shape[-1]\n",
    "print(env.action_space)\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "model = SAC(\"MlpPolicy\", env, action_noise=action_noise, verbose=1)\n",
    "model.learn(total_timesteps=10000, log_interval=10)\n",
    "model.save(\"./saved_models/sac_piecewiseReward\")\n",
    "env = model.get_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "401f889e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(-1.0, 1.0, (1,), float32)\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.4     |\n",
      "|    ep_rew_mean     | -16.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 10       |\n",
      "|    fps             | 26       |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 224      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.993    |\n",
      "|    critic_loss     | 0.238    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 122      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.9     |\n",
      "|    ep_rew_mean     | -15.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 27       |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 437      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.44     |\n",
      "|    critic_loss     | 0.324    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 321      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 47.8     |\n",
      "|    ep_rew_mean     | -41      |\n",
      "| time/              |          |\n",
      "|    episodes        | 30       |\n",
      "|    fps             | 27       |\n",
      "|    time_elapsed    | 52       |\n",
      "|    total_timesteps | 1433     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.15     |\n",
      "|    critic_loss     | 0.413    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1298     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 41.9     |\n",
      "|    ep_rew_mean     | -34.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 27       |\n",
      "|    time_elapsed    | 61       |\n",
      "|    total_timesteps | 1674     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.5      |\n",
      "|    critic_loss     | 0.426    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1559     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 40       |\n",
      "|    ep_rew_mean     | -31      |\n",
      "| time/              |          |\n",
      "|    episodes        | 50       |\n",
      "|    fps             | 27       |\n",
      "|    time_elapsed    | 74       |\n",
      "|    total_timesteps | 1999     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.88     |\n",
      "|    critic_loss     | 0.247    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1879     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 38.4     |\n",
      "|    ep_rew_mean     | -28.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 26       |\n",
      "|    time_elapsed    | 85       |\n",
      "|    total_timesteps | 2305     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.13     |\n",
      "|    critic_loss     | 0.209    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2214     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 37.2     |\n",
      "|    ep_rew_mean     | -26.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 70       |\n",
      "|    fps             | 27       |\n",
      "|    time_elapsed    | 96       |\n",
      "|    total_timesteps | 2603     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.23     |\n",
      "|    critic_loss     | 0.208    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2456     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 36.9     |\n",
      "|    ep_rew_mean     | -25      |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 26       |\n",
      "|    time_elapsed    | 109      |\n",
      "|    total_timesteps | 2948     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.31     |\n",
      "|    critic_loss     | 0.095    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2846     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 96.2     |\n",
      "|    ep_rew_mean     | -23.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 90       |\n",
      "|    fps             | 27       |\n",
      "|    time_elapsed    | 315      |\n",
      "|    total_timesteps | 8659     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.11     |\n",
      "|    critic_loss     | 0.0293   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7348     |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "from envs.pendulum_piecewiseReward import PendulumEnv as piecewise\n",
    "\n",
    "env = piecewise(render_mode='human')\n",
    "\n",
    "n_actions = env.action_space.shape[-1]\n",
    "print(env.action_space)\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "model = DDPG(\"MlpPolicy\", env, action_noise=action_noise, verbose=1)\n",
    "model.learn(total_timesteps=10000, log_interval=10)\n",
    "model.save(\"./saved_models/ddpg_piecewiseReward\")\n",
    "env = model.get_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eb8cfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(-1.0, 1.0, (1,), float32)\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.6     |\n",
      "|    ep_rew_mean     | -17.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 10       |\n",
      "|    fps             | 28       |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 226      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.202   |\n",
      "|    critic_loss     | 0.222    |\n",
      "|    ent_coef        | 0.963    |\n",
      "|    ent_coef_loss   | -0.0627  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 125      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.9     |\n",
      "|    ep_rew_mean     | -15.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 28       |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 437      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.183   |\n",
      "|    critic_loss     | 0.128    |\n",
      "|    ent_coef        | 0.904    |\n",
      "|    ent_coef_loss   | -0.168   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 336      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.4     |\n",
      "|    ep_rew_mean     | -15      |\n",
      "| time/              |          |\n",
      "|    episodes        | 30       |\n",
      "|    fps             | 28       |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 701      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.101   |\n",
      "|    critic_loss     | 0.377    |\n",
      "|    ent_coef        | 0.836    |\n",
      "|    ent_coef_loss   | -0.298   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 600      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.9     |\n",
      "|    ep_rew_mean     | -15.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 28       |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 876      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.0659  |\n",
      "|    critic_loss     | 0.452    |\n",
      "|    ent_coef        | 0.793    |\n",
      "|    ent_coef_loss   | -0.383   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 775      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.8     |\n",
      "|    ep_rew_mean     | -15.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 50       |\n",
      "|    fps             | 28       |\n",
      "|    time_elapsed    | 39       |\n",
      "|    total_timesteps | 1140     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.432    |\n",
      "|    critic_loss     | 0.624    |\n",
      "|    ent_coef        | 0.733    |\n",
      "|    ent_coef_loss   | -0.513   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1039     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.4     |\n",
      "|    ep_rew_mean     | -15.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 28       |\n",
      "|    time_elapsed    | 50       |\n",
      "|    total_timesteps | 1467     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.999    |\n",
      "|    critic_loss     | 0.533    |\n",
      "|    ent_coef        | 0.666    |\n",
      "|    ent_coef_loss   | -0.675   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1366     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 27.9     |\n",
      "|    ep_rew_mean     | -16      |\n",
      "| time/              |          |\n",
      "|    episodes        | 70       |\n",
      "|    fps             | 29       |\n",
      "|    time_elapsed    | 67       |\n",
      "|    total_timesteps | 1951     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.797    |\n",
      "|    critic_loss     | 0.512    |\n",
      "|    ent_coef        | 0.578    |\n",
      "|    ent_coef_loss   | -0.857   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1850     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33       |\n",
      "|    ep_rew_mean     | -15.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 29       |\n",
      "|    time_elapsed    | 90       |\n",
      "|    total_timesteps | 2639     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.0361  |\n",
      "|    critic_loss     | 0.193    |\n",
      "|    ent_coef        | 0.475    |\n",
      "|    ent_coef_loss   | -1.11    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 2538     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 105      |\n",
      "|    ep_rew_mean     | -15.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 90       |\n",
      "|    fps             | 29       |\n",
      "|    time_elapsed    | 315      |\n",
      "|    total_timesteps | 9442     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.77    |\n",
      "|    critic_loss     | 0.0143   |\n",
      "|    ent_coef        | 0.0665   |\n",
      "|    ent_coef_loss   | -3.41    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9341     |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "from envs.pendulum_penalizeDeflection import PendulumEnv as penalize\n",
    "\n",
    "env = penalize(render_mode='human')\n",
    "\n",
    "n_actions = env.action_space.shape[-1]\n",
    "print(env.action_space)\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "model = SAC(\"MlpPolicy\", env, action_noise=action_noise, verbose=1)\n",
    "model.learn(total_timesteps=10000, log_interval=10)\n",
    "model.save(\"./saved_models/sac_penalizeDeflection\")\n",
    "env = model.get_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5a97f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(-1.0, 1.0, (1,), float32)\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 34.3     |\n",
      "|    ep_rew_mean     | -14.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 10       |\n",
      "|    fps             | 27       |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 343      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.728    |\n",
      "|    critic_loss     | 0.207    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 211      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 129      |\n",
      "|    ep_rew_mean     | -30      |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 27       |\n",
      "|    time_elapsed    | 95       |\n",
      "|    total_timesteps | 2581     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.241   |\n",
      "|    critic_loss     | 0.0273   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2502     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 289      |\n",
      "|    ep_rew_mean     | -22.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 30       |\n",
      "|    fps             | 27       |\n",
      "|    time_elapsed    | 315      |\n",
      "|    total_timesteps | 8672     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.13    |\n",
      "|    critic_loss     | 0.0186   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7431     |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "from envs.pendulum_penalizeDeflection import PendulumEnv as penalize\n",
    "\n",
    "env = penalize(render_mode='human')\n",
    "\n",
    "n_actions = env.action_space.shape[-1]\n",
    "print(env.action_space)\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "model = DDPG(\"MlpPolicy\", env, action_noise=action_noise, verbose=1)\n",
    "model.learn(total_timesteps=10000, log_interval=10)\n",
    "model.save(\"./saved_models/ddpg_penalizeDeflection\")\n",
    "env = model.get_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa1a4dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
